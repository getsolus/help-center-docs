"use strict";(self.webpackChunksolus_help_center=self.webpackChunksolus_help_center||[]).push([[4031],{4108:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"clean-clean-clean","metadata":{"permalink":"/blog/clean-clean-clean","source":"@site/devlog/2024-11-21-clean-cleanl-clean.md","title":"Clean, clean, clean!","description":"Hello everyone! Alfi here, member of Solus Cleanup Crew. It\'s been more than a year since I started contributing to Solus and I want to talk about it. About what I did, what we did, what we accomplished so far, and what we want to do next.","date":"2024-11-21T00:00:00.000Z","tags":[{"inline":true,"label":"housekeeping","permalink":"/blog/tags/housekeeping"},{"inline":true,"label":"cleanup","permalink":"/blog/tags/cleanup"},{"inline":true,"label":"devlog","permalink":"/blog/tags/devlog"},{"inline":true,"label":"solus","permalink":"/blog/tags/solus"}],"readingTime":5.585,"hasTruncateMarker":true,"authors":[{"name":"Muhammad Alfi Syahrin","title":"Solus Staff","page":{"permalink":"/blog/authors/alfi"},"socials":{"github":"https://github.com/malfisya"},"imageURL":"https://avatars.githubusercontent.com/u/101771435","key":"alfi"}],"frontMatter":{"title":"Clean, clean, clean!","slug":"clean-clean-clean","authors":"alfi","tags":["housekeeping","cleanup","devlog","solus"],"hide_table_of_contents":false},"unlisted":false,"nextItem":{"title":"Intro to Optimizing Packages on Solus","permalink":"/blog/solus-optimizing-packages"}},"content":"Hello everyone! Alfi here, member of Solus Cleanup Crew. It\'s been more than a year since I started contributing to Solus and I want to talk about it. About what I did, what we did, what we accomplished so far, and what we want to do next.\\n\\n\x3c!-- truncate --\x3e\\n\\n## A bit of background\\n\\nI started contributing in October 2023, when Solus participated in [Hacktoberfest](https://getsol.us/2023/10/01/solus-and-hacktoberfest-2023/). Hacktoberfest is a month-long event that encourage people to contribute to open source project in exchange for some digital merchandise. Finally, an excuse to contribute to something I use every day. Although, as an accountant, all of this is new experience to me. It was confusing at first, but I persisted. Finally, I got the hang of it and I managed to submit around 100 pull request during the month of the event. I was very excited and motivated. During the month, a few people joined the event and contributed to Solus, but then November came and most of the contribution slowed down. I was the only one left that continued doing the beginner tasks, mostly adding homepage to packages.\\n\\nAt the start of January 2024, Jakob Gezelius ([androidnisse](https://github.com/androidnisse)) comes in and starts contributing to homepage task too. Worried that we would stepped on each other\'s feet, we started a private chat to organize the tasks between ourselves. Until May, the two of us had been chipping away at the homepage task which at this point left 650 packages without a homepage. Then we had more contributors joining. I decided to make a group chat to accommodate all the people joining. It was called \\"Solus Homepage Team\\" at the time. More contributors and staff members joined the room, then it was renamed as \\"Solus Cleanup Crew\\" and moved under the official Solus matrix space.\\n\\n## What is it?\\n\\nSolus cleanup crew is a group of community contributors as as well staff members with the goal of bringing the Solus package repository up to current standard. It is a subset of the packaging room on our matrix channel. We organize the work on all the cleanup related tasks.\\n\\n## Why bother?\\n\\nSolus has been updating their tooling and infrastructure since its resurrection. While most of the tooling changes can be accomplished by staff members alone, there are things that they cannot do. While many consider Solus repository as small, it still contains more than 6000 packages. Some packages have never even gotten an update since Solus was first created! We want to get rid of all its cruft before we can migrate to a better tooling. That\'s where the community contributor can come in and help.\\n\\nFor me personally, it is a chance to learn something new and fill my time with more purpose. Sometimes, I feel like a slob scrolling through things, opening the same three apps over and over or sleeping midday. Technically speaking, doing packaging is still scrolling through things, still opening the same three apps over and over, and I still get my midday nap, but now it is with purpose. I love that what I do can be enjoyed by other people. It is mostly invisible and not even noticed by people, but the chance of it helping people gives me so much joy. Why bother? Because I love it.\\n\\n## What we accomplished\\n\\nWe create a few repository wide task that can done with little reading of our packaging guide. The keen-eyed of you may have already seen these tasks. It is always attached at the end of every Sync Updates since July. These are the tasks we did:\\n|No. | Task | Date Started | Start count | Current count|\\n|----|-------------| ------| ------------|--------------|\\n|1.| [Adding homepage key to package.yml](https://github.com/getsolus/packages/issues/411)|30-09-2023|2300|8\\n|2.| [Adding AppStream metainfo to all font packages](https://github.com/getsolus/packages/issues/449)|06-10-2023| 38 | Done \ud83c\udf89|\\n|3.| [Adding AppStream metainfo to all graphical applications](https://github.com/getsolus/packages/issues/1389)|22-01-2024|316|198|\\n|4.| [Applying new cargo macros](https://github.com/getsolus/packages/issues/3111)|27-06-2024|37| Done \ud83c\udf89|\\n|5.| [Changing all packages with homepages pointing to wiki.gnome.org](https://github.com/getsolus/packages/issues/4116)|20-10-2024|87|62|\\n|6.| [Adding monitoring.yml](https://github.com/getsolus/packages/issues/4121)|21-10-2024|3070|2937|\\n|7.| [Tagging packages that do not build](https://github.com/getsolus/packages/issues?q=is%3Aopen+is%3Aissue+label%3A%22Packaging+Problem%22)|Ongoing| N/A| 13\\n|8.| [Tagging packages that should be deprecated](https://github.com/getsolus/packages/issues?q=is%3Aopen+is%3Aissue+label%3A%22Package%3A+Removal+Request%22)|Ongoing| N/A| 25\\n\\nAs you can see from the table above, we just completed two tasks and we are close to completing homepage task. Packages that do not build also are also getting solved one by one. Right now, there are 12 people in Solus Cleanup Crew Matrix room, 6 of them are new contributors. We also create a new AppStream metainfo documentation, clean up our issue templates, implement a better tagging system for organizing issues and much more. Solus Cleanup Crew is also becoming a place where we can onboard new contributors and recruit new staff. I thought we accomplished a lot and I am happy with it.\\n\\n## What next?\\n\\nWe want to focus on adding appstream metainfo for remaining 200 packages, in line with the goal of 4.7 ISO. It will not be easy nor quick, but we will try our best. We want Solus users to have the best experience possible when we finally say goodbye to `solus-sc` and switch to modern software center (Gnome Software and KDE Discover). We want you to be able to install all graphical application from software center and have all the relevant information (Legible screenshot, Hi-Res Icon, good description, etc).\\n\\nWe also want to add more [monitoring.yml](https://help.getsol.us/docs/packaging/monitoring.yml) files to packages, so we can utilize our proof-of-concept [\\"Package Update Monitor\\"](https://shared.getsol.us/justin/updates/) created by [Justin Zobel](https://github.com/Justinzobel). I, myself and [Joey Riches](https://github.com/joebonrichie) will explore the possibility of curating our own \\"Editor\'s Choice\\" and \\"Featured Apps\\" in Gnome Software, made possible by [`gnome-app-list`](https://gitlab.gnome.org/GNOME/gnome-app-list). I think the road ahead is very exciting for us and hopefully for you too!\\n\\n## Want to help?\\n\\nWe are always eager for people to join and spend their time contributing to Solus. There are many ways you can [contribute](https://help.getsol.us/docs/user/contributing/getting-involved), but for me it is packaging. For me, packaging can be relaxing, sometimes frustrating, but always gives me joy at the end. If you are interested to dip your toe on packaging and want to help us, here are the simple steps:\\n\\n1. Join the Solus Packaging Room on Matrix\\n2. Read and practice our [packaging documentation](https://help.getsol.us/docs/packaging/)\\n3. Submit your first Pull Request. We recommend doing the wiki gnome task or monitoring task\\n4. Follow along the review process until your PR gets merged\\n5. Continue on contributing and you might get invited to Solus Cleanup Crew\\n\\n## Closing thoughts\\n\\nI want to thank all the contributors that made all of this possible. It was such a wonderful effort from everyone and we will strive to keep that up. Let me know if you are interested in a follow-up blog about the detail of doing packaging for Solus. _Terima kasih dan sampai jumpa_!"},{"id":"solus-optimizing-packages","metadata":{"permalink":"/blog/solus-optimizing-packages","source":"@site/devlog/2024-02-09-Intro-to-optimizing-packages-on-solus.md","title":"Intro to Optimizing Packages on Solus","description":"Explore how to employ advanced compiler techniques such as PGO, BOLT & Glibc HWCaps to squeeze extra performance from packages using libwebp as a test vehicle","date":"2024-02-09T00:00:00.000Z","tags":[{"inline":true,"label":"pgo","permalink":"/blog/tags/pgo"},{"inline":true,"label":"lto","permalink":"/blog/tags/lto"},{"inline":true,"label":"solus","permalink":"/blog/tags/solus"},{"inline":true,"label":"packaging","permalink":"/blog/tags/packaging"},{"inline":true,"label":"optimization","permalink":"/blog/tags/optimization"},{"inline":true,"label":"3","permalink":"/blog/tags/3"},{"inline":true,"label":"clang","permalink":"/blog/tags/clang"},{"inline":true,"label":"gnu","permalink":"/blog/tags/gnu"},{"inline":true,"label":"llvm","permalink":"/blog/tags/llvm"},{"inline":true,"label":"glibc","permalink":"/blog/tags/glibc"},{"inline":true,"label":"hwcaps","permalink":"/blog/tags/hwcaps"},{"inline":true,"label":"x86_64-v3","permalink":"/blog/tags/x-86-64-v-3"}],"readingTime":22.32,"hasTruncateMarker":true,"authors":[{"name":"Joey Riches","title":"Solus Staff","page":{"permalink":"/blog/authors/joey"},"socials":{"github":"https://github.com/joebonrichie"},"imageURL":"https://avatars.githubusercontent.com/u/5338090","key":"joey"}],"frontMatter":{"title":"Intro to Optimizing Packages on Solus","description":"Explore how to employ advanced compiler techniques such as PGO, BOLT & Glibc HWCaps to squeeze extra performance from packages using libwebp as a test vehicle","slug":"solus-optimizing-packages","authors":"joey","tags":["pgo","lto","solus","packaging","optimization","3","clang","gnu","llvm","glibc","hwcaps","x86_64-v3"],"hide_table_of_contents":false},"unlisted":false,"prevItem":{"title":"Clean, clean, clean!","permalink":"/blog/clean-clean-clean"},"nextItem":{"title":"Don\'t call me MATE, pal!","permalink":"/blog/don\'t-call-me-mate-pal"}},"content":"We\'ll explore how to build packages with advanced compiler techniques in order to squeeze more performance out of the box for packages in Solus. We\'ll be using the story of how `libwebp` was optimized for and how it led to an unexpected side quest.\\n\\n\x3c!-- truncate --\x3e\\n\x3c!-- cspell:disable-next-line --\x3e\\n\\n# Cual es la causa\\n\\nLinux distributions have a lot of control over how a source-based package gets compiled and shipped to users as part of a binary repository. Aggressive and advanced compiler optimization techniques, as well as other methods can be used to provide greater out of the box performance for end users. This can greatly benefit users running on older hardware to provide a snappier end-user experience; reducing time waiting on a heavy workload to finish; or even improved battery life; amongst other improvements.\\n\\nPart of the problem is, a packager\'s time is limited. So how, as a distribution, do you choose to try provide faster compatible packages for an end user. A historic approach is to simply change the default compiler flags for _all_ packages, such as enabling [LTO](https://en.wikipedia.org/wiki/Interprocedural_optimization) by default. Whilst this approach can work well, at Solus the philosophy is slightly different where a packager can trivially enable several advanced compiler optimization techniques such as [PGO](https://en.wikipedia.org/wiki/Profile-guided_optimization) without too much faffing around on a _targeted_ package.\\n\\nThe benefits of such an approach are:\\n\\n- Can target the performance of a specific package to benefit _all_ users\\n- A compiler optimization may improve one package, but may not apply globally to all packages.\\n\\nThe downsides are such:\\n\\n- Requires additional packager time to benchmark and experiment with different optimization strategies.\\n- Requires the packager to _choose_ and invest time into improving performance of a package.\\n- Requires the packager to find an appropriate benchmark to test the package against.\\n- Experimenting with compiler optimizations may not bear fruit: no meaningful improvement in performance, or there may be some other bottleneck.\\n\\n# Optimization Techniques Available\\n\\n- speed:\\n  - As simple as it gets really, build a package with `-O3` instead of `-O2` as well as any other flags deemed worthy to be included as part of the `speed` flags. The main drawback of this is that `-O3` is not guaranteed to produce faster results than building with `-O2` and typically will produce bigger binaries. The days of `-O3` outright breaking your program in weird unexpected ways is largely behind us.\\n- LTO:\\n  - Compared to some other distributions `-flto` is not yet enabled by default on Solus. LTO is almost guaranteed to provide a %1 or slightly larger performance improvement as well as a smaller binary at the cost of increased compiling times and memory usage during build. When combined with other optimization techniques such as PGO the LTO optimization can really stretch its legs and provide even greater uplift!\\n- Clang:\\n  - Not strictly an optimization, but, building a package with `clang` instead of `gcc` and `ld.ldd` to link instead of the infamous `ld.bfd` may provide a faster package out of the box. You\'ll have to be careful of subtle ABI differences if building with `clang`. If in doubt, and, `clang` is the obvious choice, perform safety rebuilds on all reverse dependencies of the package.\\n- PGO:\\n  - Profile guided optimization. Build once with instrumentation in order to collect profile data when ran. Run the program using a representative workload in order to collect profiling data. Build the program again with the profiling data provided in order to build an optimized variant.\\n- BOLT:\\n  - Binary optimization and layout tool. You can think of this as \\"post-link PGO\\" where you instrument a binary with `bolt` to collect profiling data. Run that binary. Then finally reorganize the binary layout using the collected profile data. This generally works better on large statically linked binaries but smaller binaries or libraries such as found in a typical package can benefit too. This optimization is still quite new.\\n\\nRegardless, that\'s enough word spaghetti, let\'s look at the process to actually optimize a package.\\n\\n# Optimizing a Package\\n\\nRight, to begin with we\'ll have to start on choosing an actual package to benchmark and optimize. I\'ve heard the `.webp` file format is becoming increasingly common on the web, slowly replacing `.png` and `.jpg` file formats due to the strong backing of Google (for better or for worst). An improvement in decoding time for `.webp` files would benefit any user using a web browser casually browsing the web.\\n\\nLet\'s have a look at the `package.yml` build recipe for `libwebp`.\\n\\n\x3c!-- prettier-ignore --\x3e\\n```yaml\\nname       : libwebp\\nversion    : 1.3.2\\nrelease    : 25\\nsource     :\\n    - https://github.com/webmproject/libwebp/archive/refs/tags/v1.3.2.tar.gz : c2c2f521fa468e3c5949ab698c2da410f5dce1c5e99f5ad9e70e0e8446b86505\\nhomepage   : https://developers.google.com/speed/webp/\\nlicense    : BSD-3-Clause\\ncomponent  : multimedia.codecs\\nsummary    : A new image format for the web\\ndescription: |\\n    WebP is a new image format that provides lossless and lossy compression for images on the web. WebP lossless images are 26% smaller in size compared to PNGs. WebP lossy images are 25-34% smaller in size compared to JPEG images at equivalent SSIM index. WebP supports lossless transparency (also known as alpha channel) with just 22% additional bytes. Transparency is also supported with lossy compression and typically provides 3x smaller file sizes compared to PNG when lossy compression is acceptable for the red/green/blue color channels.\\nemul32     : yes\\npatterns   :\\n    - devel : /usr/share/man\\nbuilddeps  :\\n    - pkgconfig32(glu)\\n    - pkgconfig32(glut)\\n    - pkgconfig32(libpng)\\n    - pkgconfig32(libtiff-4)\\n    - pkgconfig32(libturbojpeg)\\n    - pkgconfig32(zlib)\\n    - giflib-devel\\nsetup      : |\\n    %reconfigure --disable-static --enable-everything\\nbuild      : |\\n    %make\\ninstall    : |\\n    %make_install\\n```\\n\\nOkay, looks to be a quite simple affair. A simple configure, make, make install as well as `emul32` being enabled specifying the -32bit packages are also provided from this recipe. Next step is to look for a repeatable and easy way to benchmark it. We\'ll begin by looking at the `pspec_x86_64.xml` file which lists all the files produced from the `package.yml` recipe as well as some metadata.\\n\\n```xml\\n        <Name>libwebp</Name>\\n        <Summary xml:lang=\\"en\\">A new image format for the web</Summary>\\n        <Description xml:lang=\\"en\\">WebP is a new image format that provides lossless and lossy compression for images on the web. WebP lossless images are 26% smaller in size compared to PNGs. WebP lossy images are 25-34% smaller in size compared to JPEG images at equivalent SSIM index. WebP supports lossless transparency (also known as alpha channel) with just 22% additional bytes. Transparency is also supported with lossy compression and typically provides 3x smaller file sizes compared to PNG when lossy compression is acceptable for the red/green/blue color channels.\\n</Description>\\n        <PartOf>multimedia.codecs</PartOf>\\n        <Files>\\n            <Path fileType=\\"executable\\">/usr/bin/cwebp</Path>\\n            <Path fileType=\\"executable\\">/usr/bin/dwebp</Path>\\n            <Path fileType=\\"executable\\">/usr/bin/gif2webp</Path>\\n            <Path fileType=\\"executable\\">/usr/bin/img2webp</Path>\\n            <Path fileType=\\"executable\\">/usr/bin/vwebp</Path>\\n            <Path fileType=\\"executable\\">/usr/bin/webpinfo</Path>\\n            <Path fileType=\\"executable\\">/usr/bin/webpmux</Path>\\n```\\n\\nPerfect, we have `dwebp` and `cwebp` binaries available in the main package, which from a guess can be used to decode and encode `.webp` files. Let\'s try it out.\\n\\n```\\n$ dwebp -h\\nUsage: dwebp in_file [options] [-o out_file]\\n\\nDecodes the WebP image file to PNG format [Default].\\nNote: Animated WebP files are not supported.\\n$ cwebp -h\\nUsage:\\n\\n   cwebp [options] -q quality input.png -o output.webp\\n```\\n\\nAwesome, these binaries do exactly what we need to benchmark `libwebp`, but, we are also indirectly testing `libpng` as well for this benchmark, we\'ll have to keep an eye out for that.\\n\\nOne extra step we have to do is ensure these binaries are actually linking against their own library, as upstream developers can have a habit of making sure their binaries don\'t link against their own libraries and end up being self-contained. Run `ldd` to verify.\\n\\n\x3c!-- spellchecker:disable --\x3e\\n\\n```\\n$ ldd /usr/bin/dwebp\\n\\tlinux-vdso.so.1 (0x00007ffed8733000)\\n\\tlibwebpdemux.so.2 => /usr/lib/libwebpdemux.so.2.0.14 (0x00007f7473bb4000)\\n\\tlibwebp.so.7 => /usr/lib/libwebp.so.7.1.8 (0x00007f7473ae2000)\\n\\tlibpng16.so.16 => /usr/lib/libpng16.so.16 (0x00007f7473aa6000)\\n\\tlibc.so.6 => /usr/lib/glibc-hwcaps/x86-64-v3/libc.so.6 (0x00007f74738a9000)\\n\\tlibsharpyuv.so.0 => /usr/lib/libsharpyuv.so.0.0.1 (0x00007f747389e000)\\n\\tlibm.so.6 => /usr/lib/glibc-hwcaps/x86-64-v3/libm.so.6 (0x00007f74737b8000)\\n\\tlibz.so.1 => /usr/lib/libz.so.1.3.0 (0x00007f7473200000)\\n\\t/usr/lib64/ld-linux-x86-64.so.2 (0x00007f7473bea000)\\n```\\n\\n\x3c!-- spellchecker:enable --\x3e\\n\\nAwesome in this case both `dwebp` and `cwebp` link against `libwebp.so` so we can be confident that any performance improvements will be applicable to all packages in the repository linking against `libwebp`.\\n\\nLet\'s grab a couple of `.webp` files from [here](https://developers.google.com/speed/webp/gallery1) to test with. We\'ll just use the largest image size available in this case to reduce noise as much as possible when running benchmarks as well as allow any potential optimizations to stretch their legs a little more.\\n\\nNow having done the prep work, lets actually benchmark the damn thing using `hyperfine` for the time being.\\n\\n```\\n$ hyperfine \\"dwebp ~/3.webp -o /dev/null\\"\\nBenchmark 1: dwebp ~/3.webp -o /dev/null\\n  Time (mean \xb1 \u03c3):     202.2 ms \xb1   0.3 ms    [User: 198.9 ms, System: 3.0 ms]\\n  Range (min \u2026 max):   201.8 ms \u2026 202.7 ms    14 runs\\n$ hyperfine \\"cwebp ~/PNG_Test.png -o /dev/null\\"\\nBenchmark 1: cwebp ~/PNG_Test.png -o /dev/null\\n  Time (mean \xb1 \u03c3):      1.423 s \xb1  0.009 s    [User: 1.346 s, System: 0.076 s]\\n  Range (min \u2026 max):    1.410 s \u2026  1.435 s    10 runs\\n```\\n\\nThere, we have our a basic baseline for encode and decode performance. We mostly care about decode performance here but improved encoding performance would also not go amiss.\\n\\n## Let\'s Start Obvious\\n\\nLet\'s start basic, enabling the `speed` optimization which basically builds with `-O3` instead of `-O2` as well as any other flags that are deemed to be worthy to be part of the `speed` group. As well as, the `lto` optimization which builds with link time optimization allowing for inter-procedural optimizations to take place.\\n\\n\x3c!-- prettier-ignore --\x3e\\n```yaml\\noptimize:\\n    - speed\\n    - lto\\n```\\n\\nMoment of truth...\\n\\n```\\n$ hyperfine \\"dwebp ~/3.webp -o /dev/null\\"\\nBenchmark 1: dwebp ~/3.webp -o /dev/null\\n  Time (mean \xb1 \u03c3):     200.0 ms \xb1   1.5 ms    [User: 197.3 ms, System: 2.5 ms]\\n  Range (min \u2026 max):   198.1 ms \u2026 203.2 ms    15 runs\\n$ hyperfine \\"cwebp ~/PNG_Test.png -o /dev/null\\"\\nBenchmark 1: cwebp ~/PNG_Test.png -o /dev/null\\n  Time (mean \xb1 \u03c3):      1.353 s \xb1  0.012 s    [User: 1.281 s, System: 0.071 s]\\n  Range (min \u2026 max):    1.336 s \u2026  1.369 s    10 runs\\n```\\n\\nWell okay, we got a very minor uplift in decoding performance and a slightly higher improvement in encoding performance, but nothing too much to write home about. Luckily we have several more optimizations to explore...\\n\\n## PGO is great, except, when it isn\'t.\\n\\nNext step is to explore PGO (Profile Guided Optimization). For our `libwebp` package, looks like we already hit a bit of a snafu. There\'s no test suite included in the tarball! That\'s a bit of a disappointment as a test suite such as `make check` is by far and away the easiest and most comprehensive workload that can be used for profiling as part of PGO, especially for smaller libraries. However, we can still experiment with the just built `dwebp` and `cwebp` binaries as a suitable workload for PGO.\\n\\nLuckily, as part of the package.yml format all you have to do is provide a profile for automatic PGO. After chrooting into the build environment and fiddling around a bit we end up with:\\n\\n\x3c!-- prettier-ignore --\x3e\\n```yaml\\nprofile    : |\\n    ./examples/dwebp webp_js/test_webp_js.webp -o test_png.png\\n    ./examples/cwebp test_png.png -o /dev/null\\n```\\n\\nAfter specifying that, 6 builds will now be performed instead of 2:\\n\\n- emul32:\\n  - Instrumented build\\n  - Run profiling workload\\n  - Optimized build using profiling data\\n- x86_64:\\n  - Instrumented build\\n  - Run profiling workload\\n  - Optimized build using profiling data\\n\\nFor this relatively small package it increases the build time from 1m1.672s to 1m42.199s\\n\\nThe next moment of truth...\\n\\n```\\n$ hyperfine \\"dwebp ~/3.webp -o /dev/null\\"\\nBenchmark 1: dwebp ~/3.webp -o /dev/null\\n  Time (mean \xb1 \u03c3):     204.1 ms \xb1   2.2 ms    [User: 201.3 ms, System: 2.7 ms]\\n  Range (min \u2026 max):   201.6 ms \u2026 207.1 ms    14 runs\\n$ hyperfine \\"cwebp ~/PNG_Test.png -o /dev/null\\"\\nBenchmark 1: cwebp ~/PNG_Test.png -o /dev/null\\n  Time (mean \xb1 \u03c3):      1.349 s \xb1  0.010 s    [User: 1.266 s, System: 0.082 s]\\n  Range (min \u2026 max):    1.335 s \u2026  1.374 s    10 runs\\n```\\n\\nWell... That\'s interesting. We actually regress in performance for decode performance whilst gaining another small bump in encoding performance. Worse still, we get a bunch of `profile count data file not found [-Wmissing-profile]` warning messages during the optimized build indicating to us our profiling workload isn\'t comprehensive enough and doesn\'t cover enough code paths. The lack of a handy `make check` that could be used as a profiling workload is really hurting us here. For now, let\'s put a pin in exploring PGO, it isn\'t a dead end but more work needs to be done curating a more comprehensive workload to chuck at it in this particular case, whilst other, easier, optimization techniques are still available to us.\\n\\n\x3c!-- cspell:disable-next-line --\x3e\\n\\n## 256 Vector Units go brrrrrr...\\n\\nThe next obvious step is to explore `glibc` hardware capabilities. For those unaware both `clang` and `gnu` compilers provide `x86_64-v2`, `x86_64-v3` and `x86_64-v4` micro-architecture build options on top of the baseline of `x86_64`. These enable the use of targeting additional CPU instruction sets during compilation for better performance. For example, `-sse4.2` for `x86_64-v2`, `-avx2` for `x86_64-v3`, and `-avx512` for `x86_64-v4`.\\n\\nWhilst that\'s great \'n all, if a program is built with `x86_64-v3` and gains an additional ~10% uplift in performance, it\'s no good if a `x86_64-v2` compatible cpu can\'t run it. Luckily the `glibc` loader that\'s found on almost general purpose linux installs provides a way to load higher or lower micro-architecture libraries if they\'re installed and supported.\\n\\nOn top of all that, the `package.yml` format provides an incredibly simple way of providing `x86_64-v3` built libraries by enabling the `avx2 : yes` flag.\\n\\nWith `avx2 : yes` enabled in the `libwebp` package three builds are performed.\\n\\n- emul32\\n- x86_64-v3\\n- x86_64\\n\\nWe now see these additional files in the `pspec_x86_64.xml` file\\n\\n```diff\\n+            <Path fileType=\\"library\\">/usr/lib64/glibc-hwcaps/x86-64-v3/libsharpyuv.so.0</Path>\\n+            <Path fileType=\\"library\\">/usr/lib64/glibc-hwcaps/x86-64-v3/libsharpyuv.so.0.0.1</Path>\\n+            <Path fileType=\\"library\\">/usr/lib64/glibc-hwcaps/x86-64-v3/libwebp.so.7</Path>\\n+            <Path fileType=\\"library\\">/usr/lib64/glibc-hwcaps/x86-64-v3/libwebp.so.7.1.8</Path>\\n+            <Path fileType=\\"library\\">/usr/lib64/glibc-hwcaps/x86-64-v3/libwebpdecoder.so.3</Path>\\n+            <Path fileType=\\"library\\">/usr/lib64/glibc-hwcaps/x86-64-v3/libwebpdecoder.so.3.1.8</Path>\\n+            <Path fileType=\\"library\\">/usr/lib64/glibc-hwcaps/x86-64-v3/libwebpdemux.so.2</Path>\\n+            <Path fileType=\\"library\\">/usr/lib64/glibc-hwcaps/x86-64-v3/libwebpdemux.so.2.0.14</Path>\\n+            <Path fileType=\\"library\\">/usr/lib64/glibc-hwcaps/x86-64-v3/libwebpmux.so.3</Path>\\n+            <Path fileType=\\"library\\">/usr/lib64/glibc-hwcaps/x86-64-v3/libwebpmux.so.3.0.13</Path>\\n```\\n\\nLet\'s rerun `lld` on `dwebp` after installing the new package and...\\n\\n\x3c!-- spellchecker:disable --\x3e\\n\\n```\\n$ ldd /usr/bin/dwebp\\n\\tlinux-vdso.so.1 (0x00007ffeab5b1000)\\n\\tlibwebpdemux.so.2 => /usr/lib/glibc-hwcaps/x86-64-v3/libwebpdemux.so.2.0.14 (0x00007f9a351d5000)\\n\\tlibwebp.so.7 => /usr/lib/glibc-hwcaps/x86-64-v3/libwebp.so.7.1.8 (0x00007f9a3510b000)\\n\\tlibpng16.so.16 => /usr/lib/libpng16.so.16 (0x00007f9a350cf000)\\n\\tlibc.so.6 => /usr/lib/glibc-hwcaps/x86-64-v3/libc.so.6 (0x00007f9a34ed2000)\\n\\tlibsharpyuv.so.0 => /usr/lib/glibc-hwcaps/x86-64-v3/libsharpyuv.so.0.0.1 (0x00007f9a34ec1000)\\n\\tlibm.so.6 => /usr/lib/glibc-hwcaps/x86-64-v3/libm.so.6 (0x00007f9a34ddb000)\\n\\tlibz.so.1 => /usr/lib/glibc-hwcaps/x86-64-v3/libz.so.1.3 (0x00007f9a34dbb000)\\n\\t/usr/lib64/ld-linux-x86-64.so.2 (0x00007f9a3520b000)\\n```\\n\\n\x3c!-- spellchecker:enable --\x3e\\n\\nWe can crucially see that `dwebp` is now loading the `x86-64-v3` built `libwebp.so` lib from `/usr/lib/glibc-hwcaps/x86-64-v3/libwebp.so.7.1.8`, success! Let\'s what our performance looks like.\\n\\n```\\n$ hyperfine \\"dwebp ~/3.webp -o /dev/null\\"\\nBenchmark 1: dwebp ~/3.webp -o /dev/null\\n  Time (mean \xb1 \u03c3):     198.2 ms \xb1   1.2 ms    [User: 195.4 ms, System: 2.5 ms]\\n  Range (min \u2026 max):   197.0 ms \u2026 200.5 ms    14 runs\\n$ hyperfine \\"cwebp ~/PNG_Test.png -o /dev/null\\"\\nBenchmark 1: cwebp ~/PNG_Test.png -o /dev/null\\n  Time (mean \xb1 \u03c3):      1.313 s \xb1  0.009 s    [User: 1.243 s, System: 0.078 s]\\n  Range (min \u2026 max):    1.308 s \u2026  1.341 s    10 runs\\n```\\n\\nLet\'s recap so far:\\n\\n| Optimization            | Decode             | Encode  | Size    |\\n| ----------------------- | ------------------ | ------- | ------- |\\n| Baseline                | 202.2 ms           | 1.399 s | 1.33 MB |\\n| Speed + LTO             | 200.0 ms           | 1.353 s | 1.73 MB |\\n| Speed + LTO + PGO       | 204.1 ms :warning: | 1.349 s | 1.07 MB |\\n| Speed + LTO + x86_64-v3 | 198.2 ms           | 1.313 s | 3.17 MB |\\n\\nWhilst we\'re still getting an additional speedup it isn\'t really anything to write home about. A measly ~2% improvement in decoding performance and a fairly respectable ~7% improvement in encoding performance for our test case. However, increasing the package size by an extra ~2MiB from providing a bunch of extra libs in `/usr/lib/glibc-hwcaps/x86-64-v3/` just ain\'t worth it. This hints that either the compiler optimizations aren\'t really effective here or we\'re being bottle-necked by something else.\\n\\nSo far, we\'ve been benchmarking fairly simply using `hyperfine`, let\'s swap that out for `perf` so we can get a callgraph.\\n\\n## Something about `perf` to the rescue\\n\\n`perf record -o dwebp.data -- dwebp ~/3.webp -o /dev/null`\\n\\n`perf record -o cwebp.data -- cwebp ~/PNG_Test.png -o /dev/null`\\n\\nLet\'s look at `dwebp` first with `perf report -i dwebp.data`.\\n\\n![Perf report dwebp](img/2024-02-09-intro-to-optimizing/perf_report_dwebp_png.webp)\\n\\nWell god damn, literally all of our time is being spent in `libz.so` it\'s no wonder our compiler optimizations were hardly improving performance.\\n\\nLet\'s also look at the `cwebp` report, we\'ve generally been getting better results from it.\\n\\n![Perf report cwebp](img/2024-02-09-intro-to-optimizing/perf_report_cwebp_png.webp)\\n\\nOkay, much more of our time is being spent in `libwebp.so` itself here which helps to explain why we were seeing a better performance uplift. Still 5.68% of our time is being spent in `libz`.\\n\\n## Choosing Wisely\\n\\nYou may remember early on, when I said we are also indirectly testing `libpng`. Well... after some more digging, that\'s exactly what\'s happening here. Re-running the `dwebp` binary it says this\\n\\n> Decodes the WebP image file to PNG format\\n\\nTurns out, it\'s more accurate to say we are _directly_ testing `libpng` and by extension `zlib`. It isn\'t `libwebp` that\'s spending all of its time in `libz.so`, it\'s `libpng`! This is exactly the reason you have to be careful about the benchmarks chosen and, ensure you understand what they\'re doing.\\n\\nHowever, the good news about this little snafu is:\\n\\n1. `dwebp` can be used to translate to another image format such as `.yuv` that\'ll more accurately remove the bottleneck from `libz.so`.\\n2. We now know that `libpng` has a huge bottleneck in `libz.so` and speeding up `zlib` _should_ dramatically speed up `libpng` performance.\\n\\n## Adjusting the Benchmark\\n\\nAfter reverting the `libwebp` package to the baseline let\'s use our adjusted decoding benchmark.\\n\\nWe\'ll now use `dwebp ~/3.webp -yuv -o /dev/null` for a decoding test, let\'s run that with `perf` to ensure we\'re exclusively testing `libwebp.so` here.\\n\\n![Perf report dwebp to yuv](img/2024-02-09-intro-to-optimizing/perf_report_dwebp_yuv.webp)\\n\\nOkay that\'s awesome, no `libpng.so` or `libz.so` to mess with our tests!\\n\\nLet\'s reapply our optimizations, keeping those which apply an uplift\\n\\n| Optimization            | Decode            | Size    |\\n| ----------------------- | ----------------- | ------- |\\n| Baseline                | 14.7 ms           | 1.33 MB |\\n| Speed                   | 14.5 ms           | 1.56 MB |\\n| LTO                     | 14.6 ms           | 1.40 MB |\\n| PGO                     | 18.0 ms :warning: | 1.07 MB |\\n| x86-64-v3               | 12.7 ms           | 2.35 MB |\\n| Speed + LTO + x86-64-v3 | 12.3 ms           | 3.17 MB |\\n\\nOkay, this is great, whilst we aren\'t getting much from speed or LTO, we are getting a big uplift from x86-64-v3 libraries and when combined with the other optimizations we\'re getting an uplift in performance of around ~16% at the cost of close to thrice the installed package size.\\n\\n### Partial Profiling\\n\\nOnce again we see that PGO regresses performance hard, however, that smaller size is giving a good hint! We already know that the profiling workload we gave it isn\'t very comprehensive due to the bunch of `-Wmissing-profile` warnings we get during the optimized build. By default, PGO will aggressively inline and apply additional optimizations to code that\'s part of the profiling workload while everything else will be optimized for size. The idea being, hot-path code is fast and code that doesn\'t matter is small. However, what happens when you can\'t craft a comprehensive workload, as seems to be the case here? Luckily GCC has a flag for exactly that `-fprofile-partial-training`. GCC docs state that:\\n\\n> In some cases it is not practical to train all possible hot paths in the program. (For example, program may contain functions specific for a given hardware and training may not cover all hardware configurations program is run on.) With -fprofile-partial-training profile feedback will be ignored for all functions not executed during the train run leading them to be optimized as if they were compiled without profile feedback. This leads to better performance when train run is not representative but also leads to significantly bigger code.\\n\\nOkay, let\'s try it out, all we need to do is specify in our `package.yml` recipe.\\n\\n\x3c!-- prettier-ignore --\x3e\\n```yaml\\nenvironment: |\\n    if [[ -n ${PGO_USE_BUILD} ]]; then\\n        export CFLAGS=\\"${CFLAGS} -fprofile-partial-training\\"\\n        export CXXFLAGS=\\"${CXXFLAGS} -fprofile-partial-training\\"\\n    fi\\n```\\n\\nAnd the results:\\n\\n| Optimization                          | Decode  | Size    |\\n| ------------------------------------- | ------- | ------- |\\n| Speed + LTO + x86-64-v3               | 12.3 ms | 3.17 MB |\\n| Speed + LTO + x86-64-v3 + Partial PGO | 12.5 ms | 3.13 MB |\\n\\nWell, it was worth a try. This highlights how useless PGO can be when you don\'t or can\'t provide it a good workload. Interestingly, we don\'t get the size bloat that was promised, in fact, the opposite.\\n\\n# Final libwebp Results\\n\\n| Benchmark                           | Time Before | Time After | Size Before | Size After |\\n| ----------------------------------- | ----------- | ---------- | ----------- | ---------- |\\n| \\"dwebp ~/3.webp -yuv -o /dev/null\\"  | 14.5 ms     | 12.3 ms    | 1.33 MB     | 3.17 MB    |\\n| \\"cwebp ~/PNG_Test.png -o /dev/null\\" | 1.399 s     | 1.313 s    | --          | --         |\\n\\nIn the end, we get a very healthy ~16% improvement in decoding from a .webp to .yuv file. As well as a respectable 6% improvement in encoding from a .png to .webp file. However, the increased package size is very unfortunate. It\'s possible to tweak the x86-64-v3 build and only ship the libs that actually improve performance in order to get the installed size back to an acceptable level.\\n\\n# \\"Next-Generation\\" Side Quest\\n\\nNow, you probably remember earlier due to our unrepresentative benchmark we found out that `libpng` is getting highly bottlenecked by `libz.so`. This now seems like a perfect opportunity to take a look at zlib and circle-back to our original benchmark that we were using.\\n\\nZlib is widely employed throughout the ecosystem and, as such you\'d think it would be highly-optimized for performance. However, that isn\'t really the case. Zlib is written in an old-fashioned way of C and tries to be _extremely_ portable; supporting dozens of systems that have fallen out of common use. As such, it\'s hard to apply architecture specific optimizations that wouldn\'t break some old system or without introducing code spaghetti. There have been a couple of attempts to merge AArch64 and x86_64 optimizations into the canonical zlib library without success.\\n\\nHowever, there is some light in this tunnel as various forks of zlib having been popping up, applying new optimizations on top of zlib. The most promising of these looks be to [zlib-ng](https://github.com/zlib-ng/zlib-ng/). When built in compatible mode, it promises to be API compatible with canonical zlib and _tries_ to be as ABI compatible as possible.\\n\\nLet\'s just go for it, replacing Solus\' `zlib` package with zlib-ng built in compatible mode. It\'s a bit scary due to how integral zlib is in a typical Linux install, but, how hard could it be?\\n\\n\x3c!-- cspell:disable-next-line --\x3e\\n\\n## I Zee a Purty lil\' Package\\n\\nWell that was simple. Here\'s what our zlib-ng `package.yml` recipe looks like.\\n\\n\x3c!-- spellchecker:disable --\x3e\\n\x3c!-- prettier-ignore --\x3e\\n```yaml\\nname       : zlib\\nversion    : 2.1.5\\nrelease    : 28\\nsource     :\\n    - https://github.com/zlib-ng/zlib-ng/archive/refs/tags/2.1.5.tar.gz : 3f6576971397b379d4205ae5451ff5a68edf6c103b2f03c4188ed7075fbb5f04\\nhomepage   : https://github.com/zlib-ng/zlib-ng\\nlicense    : ZLIB\\ncomponent  : system.base\\nsummary    : zlib replacement with optimizations for next generation systems.\\ndescription:\\n    - A zlib data compression library for the next generation systems. ABI/API compatible mode.\\ndevel      : yes\\nemul32     : yes\\nsetup      : |\\n    %cmake_ninja \\\\\\n        -DZLIB_COMPAT=ON \\\\\\n        -DWITH_GTEST=OFF \\\\\\n        -DBUILD_SHARED_LIBS=ON \\\\\\n        -DINSTALL_LIB_DIR=%libdir%\\nbuild      : |\\n    %ninja_build\\ninstall    : |\\n    %ninja_install\\ncheck      : |\\n    %ninja_check\\n```\\n\\n\x3c!-- spellchecker:enable --\x3e\\n\\nAfter building it, all the files seem to be in the right place and the test suite is passing. Let\'s just install it overwriting our canonical `zlib` package and hope our system doesn\'t die... I think the word is YOLO.\\n\\n```\\n$ hyperfine \\"dwebp ~/3.webp -o /dev/null\\"\\nBenchmark 1: dwebp ~/3.webp -o /dev/null\\n  Time (mean \xb1 \u03c3):     198.6 ms \xb1   2.3 ms    [User: 194.3 ms, System: 3.6 ms]\\n  Range (min \u2026 max):   196.3 ms \u2026 203.3 ms    14 runs\\n$ sudo eopkg it zlib-2.1.5-28-1-x86_64.eopkg\\n...\\n$ $ hyperfine \\"dwebp ~/3.webp -o /dev/null\\"\\nBenchmark 1: dwebp ~/3.webp -o /dev/null\\n  Time (mean \xb1 \u03c3):      87.6 ms \xb1   0.7 ms    [User: 84.7 ms, System: 2.6 ms]\\n  Range (min \u2026 max):    86.5 ms \u2026  88.7 ms    33 runs\\n```\\n\\nWell, hot diggity damn. Swapping out the zlib package for a more performant variant has instantly more than halved(!!) our decoding time.\\n\\nWe need to find a more contained `libpng` benchmark here that removes the `libwebp` stuff to really confirm the findings here. After some sleuthing the `libpng` source repository has a [pngtopng.c](https://github.com/glennrp/libpng/blob/libpng16/contrib/examples/pngtopng.c) file we can compile to use the system libpng library.\\n\\nChanging the header from `#include \\"../../png.h\\"` to `#include <png.h>` then running `gcc -Ofast pngtopng.c -lpng16 -o pngtopng` to compile it, we have a libpng benchmark. We can reuse our test .png file from earlier. Ending up with: `./pngtopng ~/PNG_Test.png /dev/null` for our benchmark.\\n\\n| Library          | Time     |\\n| ---------------- | -------- |\\n| zlib (canonical) | 1.464 s  |\\n| zlib-ng (compat) | 896.6 ms |\\n\\nWell. This is pretty much inline with our flawed `dwebp` benchmark from earlier. Swapping out zlib almost halves `libpng` decoding time.\\n\\n## Squeezing more from zlib-ng\\n\\nHowever, we\'re not done yet. We still have our compiler optimizations available to us to squeeze more performance from `zlib-ng`.\\n\\n| Optimization                  | Decode   | Size      |\\n| ----------------------------- | -------- | --------- |\\n| Baseline                      | 896.6 ms | 141.00 KB |\\n| Speed                         | 883.6 ms | 182.00 KB |\\n| LTO                           | 892.7 ms | 133.00 KB |\\n| PGO                           | 894.6 ms | 141.00 KB |\\n| x86-64-v3                     | 892.5 ms | 295.00 KB |\\n| Speed + LTO                   | 882.6 ms | 170.00 KB |\\n| Speed + LTO + PGO + x86-64-v3 | 882.5 ms | 250.00 KB |\\n\\nIt looks like in this case the simple speed + LTO optimizations is the way to go. Speed gives the majority of the speedup but LTO helps bring back down the package size again. However, it\'s only a 1.5% improvement from baseline for this benchmark. We can always re-benchmark it later, testing zlib performance more directly instead of via libpng. It shows how good a job the zlib-ng developers have done that it\'s so performant right out of the gate.\\n\\n# Final Words\\n\\nWe\'ve shown the process of how a package can be optimized in Solus, through the failings and wins here I hope some good tips and tricks were provided in avoiding common pitfalls. Additional benchmarking strategies such as BOLT or Polly optimizations were not discussed and it\'ll be good material for a future blog post.\\n\\nSome other important things such as tweaking the system for benchmarking in order to get representative and consistent results were also not discussed. This is especially important in power budget constrained systems such as laptops and worth bearing in mind.\\n\\nRegardless, I hope the story of how `libwebp` was optimized for was entertaining and some things were learnt for anyone looking to optimize packages in Solus for the future."},{"id":"don\'t-call-me-mate-pal","metadata":{"permalink":"/blog/don\'t-call-me-mate-pal","source":"@site/devlog/2024-01-29-dont-call-me-mate.md","title":"Don\'t call me MATE, pal!","description":"Back in our 4.4 release post we announced that Solus would stop shipping a MATE ISO, mostly because MATE showed no signs of moving away from X11 and towards wayland. At the beginning of this year, we shipped our new XFCE ISO as a beta. And now we\'re getting ready to ship the Solus MATE Transition Tool to move existing users off of MATE.","date":"2024-01-29T00:00:00.000Z","tags":[{"inline":true,"label":"MATE","permalink":"/blog/tags/mate"},{"inline":true,"label":"devlog","permalink":"/blog/tags/devlog"},{"inline":true,"label":"solus","permalink":"/blog/tags/solus"}],"readingTime":2.645,"hasTruncateMarker":true,"authors":[{"name":"David Harder","title":"Solus Staff","page":{"permalink":"/blog/authors/david"},"socials":{"github":"https://github.com/davidjharder"},"imageURL":"https://avatars.githubusercontent.com/u/23007135","key":"david"}],"frontMatter":{"title":"Don\'t call me MATE, pal!","slug":"don\'t-call-me-mate-pal","authors":"david","tags":["MATE","devlog","solus"],"hide_table_of_contents":false},"unlisted":false,"prevItem":{"title":"Intro to Optimizing Packages on Solus","permalink":"/blog/solus-optimizing-packages"},"nextItem":{"title":"eopkg is dead, long live eopkg","permalink":"/blog/eopkg-is-dead-long-live-eopkg"}},"content":"Back in our [4.4 release post](https://getsol.us/2023/07/08/solus-4-4-released/) we announced that Solus would stop shipping a MATE ISO, mostly because MATE showed no signs of moving away from X11 and towards wayland. At the beginning of this year, we shipped our new XFCE ISO as a beta. And now we\'re getting ready to ship the _Solus MATE Transition Tool_ to move existing users off of MATE.\\n\\n\x3c!-- truncate --\x3e\\n\\n## The problem\\n\\nMATE and XFCE are similar enough that eager Solusians can, and have, installed XCFE on their MATE machines with nothing more than a couple of `eopkg` commands. We\'re pretty sure our resident `bash` script enthusiast (ermo) could hammer out a working transition script in an evening. But we want a more polished experience. We know _you_ follow Solus news; after all, you\'re reading this. However, we assume there are users who dutifully update their systems, but have no interest in keeping up with our blog posts. How do we get their attention and prompt them to move away from MATE?\\n\\n## Introducing the Solus MATE Transition Tool\\n\\nWe\'re pleased to show off the _MATE Transition Tool_, which we plan to include in normal updates to MATE systems in the coming weeks. Most of the work on this tool was done by Joey; more on his efforts in the section below. Here\'s how MATE users will encounter the tool:\\n\\n:::note\\n\\nThese screenshots are current as of the publishing of this post, we may change things as we continue testing.\\n\\n:::\\n\\n1. Users will get a notification on every start-up informing them that they need to transition away from MATE.\\n\\n![Notification: Solus Transition Service](img/2024-01-29-dont-call-me-mate/notification.png)\\n\\n2. Clicking on that notification will launch the Solus MATE Transition Tool.\\n\\n![MATE Transition Tool Launch](img/2024-01-29-dont-call-me-mate/MTT-launch.png)\\n\\n3. Users select either Solus Budgie or Solus XFCE. The tool installs the selected edition, removes MATE, and prompts for a reboot\\n4. The tool removes itself after a successful transition.\\n\\nSimple. At least, that\'s what we want users to think.\\n\\n## How the Mate Transition Tool is actually part of our Python2 work\\n\\nThe story of the MATE Transition Tool is actually tied up in our fight to drag `eopkg` into the current decade. As I wrote previously, we\'re somewhat embarrassed by the amount of Solus tooling which _still_ relies on Python2. One such tool is the Solus Software Center `solus-sc`. A while back, the team decided the sane thing to do was to ditch `solus-sc` in favor of _KDE Discover_ and _GNOME Software_ . This would have the additional benefit of promoting flatpak applications to first-class citizens. The problem is _Discover_ and _Software_ have no way to talk to our package manager `eopkg`. We need an API. Luckily, other projects have encountered the same issue, leading to [`packagekit`](https://www.freedesktop.org/software/PackageKit/pk-intro.html).\\n\\nJoey has been doing the dirty work of bolting `packagekit` support onto `eopkg`, and saw an opportunity: If `eopkg` could be upgraded to understand some of `packagekit`, then he could write a special-purpose application to move users off MATE without asking them to run scary bash scripts (sorry ermo). We\'re rather pleased with this solution. MATE users get a simple transition and Solus gets closer to checking `solus-sc` off [the list.](https://github.com/getsolus/packages/issues/270)"},{"id":"eopkg-is-dead-long-live-eopkg","metadata":{"permalink":"/blog/eopkg-is-dead-long-live-eopkg","source":"@site/devlog/2024-01-19-eopkg-is-dead.md","title":"eopkg is dead, long live eopkg","description":"Close watchers of our packages repository may have noticed some strange looking items:","date":"2024-01-19T00:00:00.000Z","tags":[{"inline":true,"label":"eopkg","permalink":"/blog/tags/eopkg"},{"inline":true,"label":"devlog","permalink":"/blog/tags/devlog"},{"inline":true,"label":"moss","permalink":"/blog/tags/moss"},{"inline":true,"label":"solus","permalink":"/blog/tags/solus"}],"readingTime":1.645,"hasTruncateMarker":true,"authors":[{"name":"David Harder","title":"Solus Staff","page":{"permalink":"/blog/authors/david"},"socials":{"github":"https://github.com/davidjharder"},"imageURL":"https://avatars.githubusercontent.com/u/23007135","key":"david"}],"frontMatter":{"title":"eopkg is dead, long live eopkg","slug":"eopkg-is-dead-long-live-eopkg","authors":"david","tags":["eopkg","devlog","moss","solus"],"hide_table_of_contents":false},"unlisted":false,"prevItem":{"title":"Don\'t call me MATE, pal!","permalink":"/blog/don\'t-call-me-mate-pal"},"nextItem":{"title":"Welcome to the Solus Devlog","permalink":"/blog/welcome-solus-devlog-v1"}},"content":"Close watchers of our [packages repository](https://github.com/getsolus/packages) may have noticed some strange looking items:\\n\\n- [Initial inclusion of eopkg4-bin](https://github.com/getsolus/packages/pull/1305)\\n- [Testing the eopkg4-bin package](https://github.com/getsolus/packages/issues/1316) Warning: Minions GIF\\n\\nIt\'s a long story.\\n\\n\x3c!-- truncate --\x3e\\n\\nOur package manager `eopkg` is written in Python2. Python2 was originally planned to hit end-of-life all the way back in 2015! So Solus contributors past and present have wrestled with three thorny issues:\\n\\n- Do we really want to just port `eopkg` to python3? Surely we could build something newer and shinier.\\n- How exactly do we want to port `eopkg` to Python3? (We\'ll call this ported version `eopkg3` for short)\\n- How do we make sure `eopkg3` works even if something goes wrong with the Python3 libraries on someone\'s machine?\\n\\nHere\'s the plan to solve this: Ikey and friends over at Serpent OS are actively building a new package manager [_moss_](https://github.com/serpent-os/moss) that we are excited about. And they\'re building it with Solus in mind as an eventual user. This will be our fix for the first problem. In the meantime, we\'re taking a pragmatic approach to the last two issues so that (frankly) we can do more exciting things.\\n\\nSheepman, Livingsilver, and others completed a [direct Python3 port](https://github.com/getsolus/eopkg/commits/python3), which we never expect our users to actually run directly like a traditional Python program. Instead, that port will be compiled into a _binary_ using [nuitka](https://nuitka.net/doc/download.html). We\'re calling this compiled `eopkg3` binary `eopkg4-bin` for now. Critically, this binary will have _no dependencies_ other than `libc`. If we can successfully swap `eopkg` with `eopkg4-bin` on user\'s machines, then we\'ve solved the last issue: Python3 can be updated without worrying about also wrecking the package manager. Got it?\\n\\nBut what about Python2? Well, now that Evan and Joey have seen off a [successful ISO release](https://getsol.us/2024/01/08/solus-4-5-released/) with a `calamares` based installer, we can cross `os-installer` [off the list](https://github.com/getsolus/packages/issues/270). And `eopkg4-bin` will let us cross off a whole bunch more. The rest of that list is a story for another day."},{"id":"welcome-solus-devlog-v1","metadata":{"permalink":"/blog/welcome-solus-devlog-v1","source":"@site/devlog/2024-01-13-welcome-devlog.md","title":"Welcome to the Solus Devlog","description":"Welcome to the Solus Development Log.","date":"2024-01-13T00:00:00.000Z","tags":[{"inline":true,"label":"hello","permalink":"/blog/tags/hello"},{"inline":true,"label":"devlog","permalink":"/blog/tags/devlog"},{"inline":true,"label":"firstpost","permalink":"/blog/tags/firstpost"},{"inline":true,"label":"solus","permalink":"/blog/tags/solus"}],"readingTime":0.9,"hasTruncateMarker":true,"authors":[{"name":"Joey Riches","title":"Solus Staff","page":{"permalink":"/blog/authors/joey"},"socials":{"github":"https://github.com/joebonrichie"},"imageURL":"https://avatars.githubusercontent.com/u/5338090","key":"joey"}],"frontMatter":{"title":"Welcome to the Solus Devlog","description":"Welcome to the Solus Development Log.","slug":"welcome-solus-devlog-v1","authors":"joey","tags":["hello","devlog","firstpost","solus"],"hide_table_of_contents":false},"unlisted":false,"prevItem":{"title":"eopkg is dead, long live eopkg","permalink":"/blog/eopkg-is-dead-long-live-eopkg"}},"content":"Welcome to the Solus Development Log.\\n\\nThe Solus Development Log will be used by Solus Staff and outside contributors to highlight wins and changes in Solus. Keep an eye on this space.\\n\\n\x3c!-- truncate --\x3e\\n\\nThe Solus DevLog has been setup to facilitate improved communication with the outside world; wins, significant changes, as well as challenges, within Solus. Solus Staff and contributors are encouraged to use this space.\\n\\nThe DevLog has been setup as a separate entity to the [Solus Blog](https://getsol.us/blog/) to encourage more short form development content that doesn\'t require the same level of polish as an official blog post.\\n\\nIt is hoped that this will be used to help communicate what\'s going on in Solus such that our short-term and medium-term progress, goals, and ambitions are less of a black box to the outside world.\\n\\nAdditionally, we believe it will help provide context to any of our murmurings for any users who keep an eye on the [getsolus](https://github.com/getsolus/) GitHub organization page and the [Solus](https://matrix.to/#/#solus:matrix.org) Matrix channels.\\n\\nHope to see you back at this space soon with more content!"}]}}')}}]);